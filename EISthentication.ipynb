{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîê Authentication"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import shap\n",
    "import sys\n",
    "import tsfresh\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from utils.const import *\n",
    "from utils.helperFunctions import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"  # Also affect subprocesses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìç Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing IDs\n",
    "ids = ['id1', 'id2', 'id3']\n",
    "# Choose what ID to process\n",
    "id = 'id1'\n",
    "ids_remove = [x for x in ids if x != id]\n",
    "\n",
    "# Filter features and keep only relevant ones\n",
    "filterFeatures = True\n",
    "\n",
    "# Undersampling\n",
    "fairUndersampling = False       # Each class same number\n",
    "targetedUndersampling = True    # Downsample most frequent class\n",
    "customBalance = False           # Downsample by specifying number of samples for each label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    'AdaBoost',\n",
    "    'Decision Tree',\n",
    "    'Gaussian Naive Bayes',\n",
    "    'Nearest Neighbors',\n",
    "    'Neural Network',\n",
    "    'Quadratic Discriminant Analysis',\n",
    "    'Random Forest',\n",
    "    'Support Vector Machine'\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    AdaBoostClassifier(random_state=SEED),\n",
    "    DecisionTreeClassifier(random_state=SEED),\n",
    "    GaussianNB(),\n",
    "    KNeighborsClassifier(),\n",
    "    MLPClassifier(random_state=SEED),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    RandomForestClassifier(random_state=SEED),\n",
    "    SVC(random_state=SEED),\n",
    "]\n",
    "\n",
    "parameters = [\n",
    "    # AdaBoostClassifier\n",
    "    {\n",
    "        'n_estimators': [50, 100, 150, 200]\n",
    "    },\n",
    "    # DecisionTreeClassifier\n",
    "    {\n",
    "        'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "        'max_depth': np.arange(3, 20)\n",
    "    },\n",
    "    # GaussianNB\n",
    "    {\n",
    "        'var_smoothing': np.logspace(0, -9, num=100)\n",
    "    },\n",
    "    # KNeighborsClassifier\n",
    "    {\n",
    "        'n_neighbors': list(range(1, 20)),\n",
    "        'weights': ['uniform', 'distance']\n",
    "    },\n",
    "    # MLPClassifier\n",
    "    {\n",
    "        'hidden_layer_sizes': [(50, ), (100, ), (200, )],\n",
    "        'activation': ['tanh', 'relu'],\n",
    "        'solver': ['adam', 'sgd']\n",
    "    },\n",
    "    # QuadraticDiscriminantAnalysis\n",
    "    {\n",
    "        'reg_param': [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "    },\n",
    "    # RandomForestClassifier\n",
    "    {\n",
    "        'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "        'n_estimators': [100, 200, 300, 400, 500]\n",
    "    },\n",
    "    # SVC\n",
    "    {\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'C': np.arange(1, 5, 1),\n",
    "        'gamma': np.arange(0.2, 1, 0.2)\n",
    "    },\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = []\n",
    "for dataset in DATASETS:\n",
    "    file = os.path.join(PROCESSED, dataset)\n",
    "    if file.split('.')[-1] == 'parquet':\n",
    "        df = pd.read_parquet(file)\n",
    "        dff.append(df)\n",
    "\n",
    "    df = pd.concat(dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "axs = axs.ravel()\n",
    "\n",
    "df['id1'].value_counts().sort_index().plot(\n",
    "    kind='bar', title='ID1 Distribution', xlabel='IDs', ylabel='Occurences', ax=axs[0])\n",
    "df['id2'].value_counts().sort_index().plot(\n",
    "    kind='bar', title='ID2 Distribution', xlabel='IDs', ylabel='Occurences', ax=axs[1])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if customBalance:\n",
    "    id1_dict = {}\n",
    "    id2_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if targetedUndersampling:\n",
    "    df_x = df.drop(id, axis=1)\n",
    "    df_x = df_x.drop(ids_remove, axis=1)\n",
    "    if customBalance:\n",
    "        X_resampled, y_resampled = RandomUnderSampler(\n",
    "            sampling_strategy=id2_dict, random_state=SEED).fit_resample(df_x, df[id])\n",
    "    else:\n",
    "        X_resampled, y_resampled = RandomUnderSampler(random_state=SEED).fit_resample(df_x, df[id])\n",
    "\n",
    "    X_resampled[id] = y_resampled\n",
    "    # for id_remove in ids_remove:\n",
    "    #     X_resampled[id_remove]\n",
    "    df = X_resampled\n",
    "\n",
    "    df[id].value_counts().sort_index().plot(\n",
    "        kind='bar', title='ID1 Distribution', xlabel='IDs', ylabel='Occurences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beforeFeat = df.shape[1]\n",
    "tsfresh.utilities.dataframe_functions.impute(df)\n",
    "\n",
    "if filterFeatures:\n",
    "    df = tsfresh.select_features(df, df[id])\n",
    "    afterFeat = df.shape[1]\n",
    "\n",
    "    print(f'[üî• FILTER]\\n\\tBefore: {beforeFeat}\\n\\tAfter: {afterFeat}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí™ Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading labels\n",
    "labels = df[id][:, np.newaxis]\n",
    "\n",
    "# Loading features\n",
    "features = df.drop(id, axis=1)\n",
    "if not targetedUndersampling:\n",
    "    for id_remove in ids_remove:\n",
    "        features = features.drop(id_remove, axis=1)\n",
    "\n",
    "# Train and test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    features, labels, test_size=0.2, random_state=SEED)\n",
    "\n",
    "cols = []\n",
    "for col in X_train.columns:\n",
    "    cols.append(col.replace('z2__', ''))\n",
    "\n",
    "X_train.columns = cols\n",
    "X_test.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "best_params = []\n",
    "\n",
    "# Iterate over classifiers\n",
    "for name, clf, param in zip(names, classifiers, parameters):\n",
    "    print(f'[ü§ñ MODEL] {name}')\n",
    "\n",
    "    grid = GridSearchCV(clf, param, n_jobs=-1, verbose=0)\n",
    "    \n",
    "    grid.fit(X_train, Y_train)\n",
    "\n",
    "    score_train = grid.best_estimator_.score(X_train, Y_train)\n",
    "    print(f'\\t[üëü TRAIN]\\t{round(score_train, 3)}')\n",
    "\n",
    "    score_test = grid.best_estimator_.score(X_test, Y_test)\n",
    "    print(f'\\t[üß™ TEST]\\t{round(score_test, 3)}\\n')\n",
    "\n",
    "    train_scores.append(score_train)\n",
    "    test_scores.append(score_test)\n",
    "    best_params.append(grid.best_params_)\n",
    "\n",
    "    # Feature importance for Random Forest\n",
    "    if name == 'Random Forest':\n",
    "        impurity = grid.best_estimator_.feature_importances_\n",
    "        std = np.std([tree.feature_importances_ for tree in grid.best_estimator_.estimators_], axis=0)\n",
    "        explainer = shap.TreeExplainer(grid.best_estimator_)\n",
    "        shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîù Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_impurity = pd.Series(impurity, index=X_train.columns).nlargest(20)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_impurity.plot.bar(ax=ax)  # , yerr=std)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "# plt.xticks(rotation = 90)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
